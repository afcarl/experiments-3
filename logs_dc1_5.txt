lr 0.003; max_mom 0.95; batch_size 64; min_mom 0.85; weight_decay 0 train_method 1CY; num_cycles 1; cycle_len (2, 4); cycle_mult 1; lr_div 10; pct_relax 0.1; optimizer Adam; beta 0.99; wd_in_loss True; snapshot_ensemble False; use_swa False; amsgrad False

Phase1
epoch      trn_loss   val_loss   metric     
    0      0.051859   0.026981   0.9895    
    1      0.03779    0.026452   0.9905    

Phase2
epoch      trn_loss   val_loss   metric     
    0      0.058405   0.049398   0.9805    
    1      0.062345   0.037664   0.9875    
    2      0.03987    0.033518   0.9835    
    3      0.013193   0.030645   0.9885    
lr 0.003; max_mom 0.95; batch_size 64; min_mom 0.85; weight_decay 0 train_method 1CY; num_cycles 1; cycle_len (2, 4); cycle_mult 1; lr_div 10; pct_relax 0.1; optimizer Adam; beta 0.99; wd_in_loss True; snapshot_ensemble False; use_swa False; amsgrad False

Phase1
epoch      trn_loss   val_loss   metric     
    0      0.044104   0.027283   0.991     
    1      0.044327   0.024574   0.9905    

Phase2
epoch      trn_loss   val_loss   metric     
    0      0.057311   0.035287   0.985     
    1      0.065439   0.059066   0.9785    
    2      0.032939   0.026923   0.991     
    3      0.011098   0.025111   0.993     
lr 0.003; max_mom 0.95; batch_size 64; min_mom 0.85; weight_decay 0 train_method 1CY; num_cycles 1; cycle_len (2, 4); cycle_mult 1; lr_div 10; pct_relax 0.1; optimizer Adam; beta 0.99; wd_in_loss True; snapshot_ensemble False; use_swa False; amsgrad False

Phase1
epoch      trn_loss   val_loss   metric     
    0      0.052319   0.032434   0.9865    
    1      0.034931   0.023709   0.9905    

Phase2
epoch      trn_loss   val_loss   metric     
    0      0.061613   0.041284   0.9845    
    1      0.064825   0.049944   0.9805    
    2      0.034684   0.035133   0.987     
    3      0.01399    0.028423   0.9895    
lr 0.003; max_mom 0.95; batch_size 64; min_mom 0.85; weight_decay 0 train_method 1CY; num_cycles 1; cycle_len (2, 4); cycle_mult 1; lr_div 10; pct_relax 0.1; optimizer Adam; beta 0.99; wd_in_loss True; snapshot_ensemble False; use_swa False; amsgrad False

Phase1
epoch      trn_loss   val_loss   metric     
    0      0.047562   0.028919   0.991     
    1      0.033025   0.023655   0.9895    

Phase2
epoch      trn_loss   val_loss   metric     
    0      0.051866   0.049802   0.9805    
    1      0.077745   0.054112   0.982     
    2      0.043108   0.028046   0.989     
    3      0.014367   0.018123   0.9935    
lr 0.003; max_mom 0.95; batch_size 64; min_mom 0.85; weight_decay 0 train_method 1CY; num_cycles 1; cycle_len (2, 4); cycle_mult 1; lr_div 10; pct_relax 0.1; optimizer Adam; beta 0.99; wd_in_loss True; snapshot_ensemble False; use_swa False; amsgrad False

Phase1
epoch      trn_loss   val_loss   metric     
    0      0.046355   0.030983   0.9895    
    1      0.040309   0.025336   0.9915    

Phase2
epoch      trn_loss   val_loss   metric     
    0      0.062371   0.037007   0.988     
    1      0.066891   0.05046    0.9855    
    2      0.03897    0.038139   0.984     
    3      0.012864   0.029193   0.989     
lr 0.003; max_mom 0.95; batch_size 64; min_mom 0.85; weight_decay 0 train_method 1CY; num_cycles 1; cycle_len (2, 4); cycle_mult 1; lr_div 10; pct_relax 0.1; optimizer Adam; beta 0.99; wd_in_loss True; snapshot_ensemble False; use_swa False; amsgrad False

Phase1
epoch      trn_loss   val_loss   metric     
    0      0.050584   0.033089   0.9905    
    1      0.033735   0.024051   0.991     

Phase2
epoch      trn_loss   val_loss   metric     
    0      0.063366   0.067952   0.972     
    1      0.06085    0.047093   0.983     
    2      0.034213   0.031829   0.9865    
    3      0.01152    0.028769   0.991     
